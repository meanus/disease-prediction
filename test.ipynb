{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41076bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>No. of Cases</th>\n",
       "      <th>Turbidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saturday, December 31, 2022 12:00:00 A.M.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saturday, December 31, 2022 3:00:00 A.M.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturday, December 31, 2022 6:00:00 A.M.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saturday, December 31, 2022 9:00:00 A.M.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saturday, December 31, 2022 12:00:00 P.M.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Wednesday, December 27, 2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Thursday, December 28, 2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Friday, December 29, 2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Saturday, December 30, 2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Sunday, December 31, 2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Time  No. of Cases  Turbidity\n",
       "0    Saturday, December 31, 2022 12:00:00 A.M.           0.0         20\n",
       "1     Saturday, December 31, 2022 3:00:00 A.M.           6.0         15\n",
       "2     Saturday, December 31, 2022 6:00:00 A.M.           1.0         19\n",
       "3     Saturday, December 31, 2022 9:00:00 A.M.           0.0         12\n",
       "4    Saturday, December 31, 2022 12:00:00 P.M.           1.0          5\n",
       "..                                         ...           ...        ...\n",
       "461               Wednesday, December 27, 2023           0.0          1\n",
       "462                Thursday, December 28, 2023           0.0          3\n",
       "463                  Friday, December 29, 2023           0.0          2\n",
       "464                Saturday, December 30, 2023           0.0          1\n",
       "465                  Sunday, December 31, 2023           0.0          0\n",
       "\n",
       "[466 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data= pd.read_csv('aligned_output.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12088dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcce2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Time']= pd.to_datetime(data['Time'])\n",
    "plt.plot(data['Time'], data['No. of Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04ef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Cases</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>No. of Cases1</th>\n",
       "      <th>Turbidity1</th>\n",
       "      <th>No. of Cases2</th>\n",
       "      <th>Turbidity2</th>\n",
       "      <th>No. of Cases3</th>\n",
       "      <th>Turbidity3</th>\n",
       "      <th>No. of Cases4</th>\n",
       "      <th>Turbidity4</th>\n",
       "      <th>No. of Cases5</th>\n",
       "      <th>Turbidity5</th>\n",
       "      <th>No. of Cases6</th>\n",
       "      <th>Turbidity6</th>\n",
       "      <th>No. of Cases7</th>\n",
       "      <th>Turbidity7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [No. of Cases, Turbidity, No. of Cases1, Turbidity1, No. of Cases2, Turbidity2, No. of Cases3, Turbidity3, No. of Cases4, Turbidity4, No. of Cases5, Turbidity5, No. of Cases6, Turbidity6, No. of Cases7, Turbidity7]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy as dc \n",
    "\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df= dc(df)\n",
    "    \n",
    "    \n",
    "    df.set_index('Time', inplace=True)\n",
    "    \n",
    "    for i in range(1, n_steps+1):\n",
    "        df[f'No. of Cases{i}']= df['No. of Cases'].shift(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "lookback= 7\n",
    "shifted_data= prepare_dataframe_for_lstm(data, lookback)\n",
    "shifted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bb15f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 16), dtype=float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_df_as_numpy= shifted_data.to_numpy()\n",
    "shifted_df_as_numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b701482",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 16)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[32m      2\u001b[39m scaler= MinMaxScaler(feature_range=(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m shifted_df_as_numpy= \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshifted_df_as_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m shifted_df_as_numpy\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MANAS KEDIA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MANAS KEDIA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:894\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    879\u001b[39m         warnings.warn(\n\u001b[32m    880\u001b[39m             (\n\u001b[32m    881\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    890\u001b[39m         )\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MANAS KEDIA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:454\u001b[39m, in \u001b[36mMinMaxScaler.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MANAS KEDIA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MANAS KEDIA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:494\u001b[39m, in \u001b[36mMinMaxScaler.partial_fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    491\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m    493\u001b[39m first_pass = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_array_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m device_ = device(X)\n\u001b[32m    503\u001b[39m feature_range = (\n\u001b[32m    504\u001b[39m     xp.asarray(feature_range[\u001b[32m0\u001b[39m], dtype=X.dtype, device=device_),\n\u001b[32m    505\u001b[39m     xp.asarray(feature_range[\u001b[32m1\u001b[39m], dtype=X.dtype, device=device_),\n\u001b[32m    506\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MANAS KEDIA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MANAS KEDIA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 16)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler(feature_range=(-1, 1))\n",
    "shifted_df_as_numpy= scaler.fit_transform(shifted_df_as_numpy)\n",
    "shifted_df_as_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a71c30e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 15), (0,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= shifted_df_as_numpy[:, 1:]\n",
    "y= shifted_df_as_numpy[:, 0]\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52baf4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2       , -1.        , -0.4       , ..., -0.92      ,\n",
       "        -0.6       , -0.2       ],\n",
       "       [-0.4       ,  1.        , -0.24      , ..., -0.2       ,\n",
       "        -0.6       , -0.28      ],\n",
       "       [-0.24      , -0.66666667, -0.52      , ..., -0.28      ,\n",
       "        -0.2       , -0.2       ],\n",
       "       ...,\n",
       "       [-0.92      , -1.        , -0.92      , ..., -0.88      ,\n",
       "        -1.        , -0.92      ],\n",
       "       [-0.92      , -1.        , -0.88      , ..., -0.92      ,\n",
       "        -1.        , -0.96      ],\n",
       "       [-0.88      , -1.        , -0.88      , ..., -0.96      ,\n",
       "        -1.        , -1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= dc(np.flip(x, axis=1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split= int(0.95 * len(x))\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c1852b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 15), (0,), (0, 15), (0,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train= x[:split]\n",
    "x_test= x[split:]\n",
    "y_train= y[:split]\n",
    "y_test= y[split:]\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85b9f05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 7, 1), (0, 7, 1), (0, 1), (0, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = x_train.reshape((-1, lookback, 1))\n",
    "X_test = x_test.reshape((-1, lookback, 1))\n",
    "\n",
    "y_train = y_train.reshape((-1, 1))\n",
    "y_test = y_test.reshape((-1, 1))\n",
    "X_train.shape, X_test.shape, y_train. shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb938d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([420, 7, 1]),\n",
       " torch.Size([23, 7, 1]),\n",
       " torch.Size([420, 1]),\n",
       " torch.Size([23, 1]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_test= torch.tensor(X_test).float()\n",
    "y_test =torch.tensor(y_test).float()\n",
    "X_train.shape, X_test.shape, y_train. shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e464cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset \n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x= x\n",
    "        self.y= y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_ds= TimeSeriesDataset(X_train, y_train)\n",
    "test_ds= TimeSeriesDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6dd13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TimeSeriesDataset at 0x274eca0b230>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3699ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size= 16\n",
    "\n",
    "train_loader= DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader= DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c65db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 7, 1]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    x_batch, y_batch= batch[0].to(device), batch[1].to(device)\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26274a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(2, 4, batch_first=True)\n",
      "  (fc): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "        self.lstm = nn. LSTM(input_size, hidden_size, num_stacked_layers,\n",
    "        batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "model = LSTM(1,4,1).to(device)\n",
    "model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190a090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch():\n",
    "    model.train (True)\n",
    "    print('Epoch: {epoch + 1}')\n",
    "    running_loss= 0.0\n",
    "    \n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        x_batch, y_batch= batch[0].to(device), batch [1].to(device)\n",
    "        \n",
    "        output = model(x_batch)\n",
    "        loss = loss_function(output, y_batch)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_index % 10 == 9: # print every 100 batches\n",
    "            avg_loss_across_batches= running_loss / 100\n",
    "            print('Batch {0}, Loss: {1:.3f}'.format(batch_index+1,avg_loss_across_batches))\n",
    "            running_loss = 0.0\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    model.train (False)\n",
    "    running_loss= 0.0\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        x_batch, y_batch=batch[0].to(device), batch [1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output= model(x_batch)\n",
    "            loss= loss_function(output, y_batch)\n",
    "            running_loss += loss\n",
    "    avg_loss_across_batches = running_loss / len(test_loader)\n",
    "    print('Val Loss: {0:.3f}'.format(avg_loss_across_batches))\n",
    "    print('******************************')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8633d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.022\n",
      "Batch 20, Loss: 0.020\n",
      "Val Loss: 0.164\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.016\n",
      "Batch 20, Loss: 0.015\n",
      "Val Loss: 0.091\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.014\n",
      "Batch 20, Loss: 0.011\n",
      "Val Loss: 0.040\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.011\n",
      "Batch 20, Loss: 0.008\n",
      "Val Loss: 0.017\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.010\n",
      "Val Loss: 0.012\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.010\n",
      "Batch 20, Loss: 0.010\n",
      "Val Loss: 0.011\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.013\n",
      "Val Loss: 0.010\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.009\n",
      "Batch 20, Loss: 0.011\n",
      "Val Loss: 0.011\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.009\n",
      "Batch 20, Loss: 0.008\n",
      "Val Loss: 0.009\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.009\n",
      "Val Loss: 0.011\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.007\n",
      "Batch 20, Loss: 0.012\n",
      "Val Loss: 0.009\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.007\n",
      "Batch 20, Loss: 0.007\n",
      "Val Loss: 0.007\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.009\n",
      "Batch 20, Loss: 0.008\n",
      "Val Loss: 0.008\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.007\n",
      "Batch 20, Loss: 0.009\n",
      "Val Loss: 0.006\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.010\n",
      "Val Loss: 0.006\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.009\n",
      "Batch 20, Loss: 0.008\n",
      "Val Loss: 0.004\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.007\n",
      "Batch 20, Loss: 0.009\n",
      "Val Loss: 0.004\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.006\n",
      "Val Loss: 0.002\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.003\n",
      "Batch 20, Loss: 0.007\n",
      "Val Loss: 0.004\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.006\n",
      "Val Loss: 0.003\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.009\n",
      "Batch 20, Loss: 0.004\n",
      "Val Loss: 0.002\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.007\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.004\n",
      "Batch 20, Loss: 0.006\n",
      "Val Loss: 0.002\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.004\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.004\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.007\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.004\n",
      "Batch 20, Loss: 0.005\n",
      "Val Loss: 0.002\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.006\n",
      "Batch 20, Loss: 0.004\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.006\n",
      "Batch 20, Loss: 0.008\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.008\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.006\n",
      "Batch 20, Loss: 0.007\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.006\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.006\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.007\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.006\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.005\n",
      "Batch 20, Loss: 0.006\n",
      "Val Loss: 0.001\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.006\n",
      "Batch 20, Loss: 0.005\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.007\n",
      "Batch 20, Loss: 0.003\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.007\n",
      "Batch 20, Loss: 0.003\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n",
      "Epoch: {epoch + 1}\n",
      "Batch 10, Loss: 0.008\n",
      "Batch 20, Loss: 0.005\n",
      "Val Loss: 0.000\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "num_epochs = 40\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim. Adam (model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573bb38",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m model.eval()\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Make predictions on the training data to see how well it learned\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     predicted = model(\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m(device)).to(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m).numpy()\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Plot the actual vs predicted values for 'No. of Cases'\u001b[39;00m\n\u001b[32m     11\u001b[39m plt.plot(y_train[:, \u001b[32m0\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mActual Cases\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# CORRECTED CELL 19 (Plotting Predictions)\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Make predictions on the training data to see how well it learned\n",
    "    predicted = model(X_train.to(device)).to('cpu').numpy()\n",
    "\n",
    "# Plot the actual vs predicted values for 'No. of Cases'\n",
    "plt.plot(y_train[:, 0], label='Actual Cases')\n",
    "plt.plot(predicted[:, 0], label='Predicted Cases')\n",
    "plt.title('Training Data: No. of Cases')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Scaled Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the actual vs predicted values for 'Turbidity'\n",
    "plt.plot(y_train[:, 1], label='Actual Turbidity')\n",
    "plt.plot(predicted[:, 1], label='Predicted Turbidity')\n",
    "plt.title('Training Data: Turbidity')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Scaled Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a5114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
